[root@sandbox-hdp ~]# hadoop jar FindMaxTemp.jar FindMaxTemp /TomWhite /TomWhite/Output
18/01/09 16:25:29 INFO client.RMProxy: Connecting to ResourceManager at sandbox-hdp.hortonworks.com/172.17.0.2:8032
18/01/09 16:25:29 INFO client.AHSProxy: Connecting to Application History server at sandbox-hdp.hortonworks.com/172.17.0.2:10200
18/01/09 16:25:29 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
18/01/09 16:25:30 INFO input.FileInputFormat: Total input paths to process : 2
18/01/09 16:25:30 INFO mapreduce.JobSubmitter: number of splits:2
18/01/09 16:25:30 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1515451368338_0059
18/01/09 16:25:31 INFO impl.YarnClientImpl: Submitted application application_1515451368338_0059
18/01/09 16:25:31 INFO mapreduce.Job: The url to track the job: http://sandbox-hdp.hortonworks.com:8088/proxy/application_1515451368338_0059/
18/01/09 16:25:31 INFO mapreduce.Job: Running job: job_1515451368338_0059
18/01/09 16:25:39 INFO mapreduce.Job: Job job_1515451368338_0059 running in uber mode : false
18/01/09 16:25:39 INFO mapreduce.Job:  map 0% reduce 0%
18/01/09 16:25:46 INFO mapreduce.Job:  map 100% reduce 0%
18/01/09 16:25:52 INFO mapreduce.Job:  map 100% reduce 100%
18/01/09 16:25:53 INFO mapreduce.Job: Job job_1515451368338_0059 completed successfully
18/01/09 16:25:54 INFO mapreduce.Job: Counters: 49
        File System Counters
                FILE: Number of bytes read=42
                FILE: Number of bytes written=458306
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=1777404
                HDFS: Number of bytes written=18
                HDFS: Number of read operations=9
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=2
        Job Counters
                Launched map tasks=2
                Launched reduce tasks=1
                Data-local map tasks=2
                Total time spent by all maps in occupied slots (ms)=9922
                Total time spent by all reduces in occupied slots (ms)=3289
                Total time spent by all map tasks (ms)=9922
                Total time spent by all reduce tasks (ms)=3289
                Total vcore-milliseconds taken by all map tasks=9922
                Total vcore-milliseconds taken by all reduce tasks=3289
                Total megabyte-milliseconds taken by all map tasks=2480500
                Total megabyte-milliseconds taken by all reduce tasks=822250
        Map-Reduce Framework
                Map input records=13130
                Map output records=13129
                Map output bytes=118161
                Map output materialized bytes=54
                Input split bytes=236
                Combine input records=13129
                Combine output records=2
                Reduce input groups=2
                Reduce shuffle bytes=54
                Reduce input records=2
                Reduce output records=2
                Spilled Records=4
                Shuffled Maps =2
                Failed Shuffles=0
                Merged Map outputs=2
                GC time elapsed (ms)=500
                CPU time spent (ms)=2750
                Physical memory (bytes) snapshot=527085568
                Virtual memory (bytes) snapshot=6414725120
                Total committed heap usage (bytes)=264765440
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters
                Bytes Read=1777168
        File Output Format Counters
                Bytes Written=18
[root@sandbox-hdp ~]# hdfs dfs -copyToLocal /TomWhite/Output/part-r-00000
